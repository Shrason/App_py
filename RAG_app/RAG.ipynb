{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('Leave No Context Behind.pdf')\n",
    "#pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key='AIzaSyDPuLLK_0j5B1yDRvUcZQFcVibSx__yZiU',model='models/embedding-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory='rag_db_')\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = Chroma(persist_directory='rag_db_', embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_connection.as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'give 5 important points from the document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_docs = retriever.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Preprint.\\n\\nUnder review.', metadata={'page': 4, 'source': 'Leave No Context Behind.pdf'}),\n",
       " Document(page_content='This approach further allows us to cast the memory update\\nand retrieval process as linear attention mechanism (Shen et al., 2018) and to leverage\\nstable training techniques from the related methods.\\n\\nSpecially, we adopt the update rule\\nand retrieval mechanism by Katharopoulos et al.\\n\\n(2020) mainly due to its simplicity and\\ncompetitive performance.\\n\\nMemory retrieval.', metadata={'page': 3, 'source': 'Leave No Context Behind.pdf'}),\n",
       " Document(page_content='We applied gradient checkpointing after each segment to save to save memory.\\n\\nThe\\nbatch size was set to 64.\\n\\nFor the LLM experiments, we set the learning rate to 0.0001 during\\ncontinual pre-training and task fine-tuning.\\n\\nB Passkey Retrieval Task\\nBelow we showed the input format of the passkey task.\\n\\nThere is an important info hidden inside a lot of irrelevant text.\\n\\nFind it and memorize them.\\n\\nI\\nwill quiz you about the important information there.\\n\\nThe grass is green.\\n\\nThe sky is blue.', metadata={'page': 11, 'source': 'Leave No Context Behind.pdf'}),\n",
       " Document(page_content='More recently, system-level optimization\\ntechniques have been proposed by leveraging specific hardware architecture to make the\\nexact attention computation more efficient (Dao et al., 2022; Liu et al., 2023).\\n\\n8', metadata={'page': 7, 'source': 'Leave No Context Behind.pdf'}),\n",
       " Document(page_content='We set the input length to 32K for fine-tuning and increase to 500K for evaluating.\\n\\nWe use a\\ngeneration temperature of 0.5 and top p=0.95 and set the number of decoding steps to 1024\\nto generate a summary of each book.\\n\\n7', metadata={'page': 6, 'source': 'Leave No Context Behind.pdf'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
